{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774b034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellem\\anaconda3\\lib\\site-packages\\spacy\\util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "text_path = \"../data/article.txt\"\n",
    "outfile = \"../data/trial.tsv\"\n",
    "\n",
    "with open(text_path, encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(content)\n",
    "\n",
    "# https://spacy.io/api/token\n",
    "token = [tok.text for tok in doc]\n",
    "dependency = [tok.dep_ for tok in doc]\n",
    "head = [tok.head for tok in doc]\n",
    "dependent = [[t.text for t in tok.children] for tok in doc]\n",
    "constituent = [[t.text for t in tok.subtree] for tok in doc]\n",
    "\n",
    "parse_info = {\"token\": token, \"dependency\": dependency,\n",
    "              \"head\": head, \"dependent\": dependent,\n",
    "              \"constituent\": constituent}\n",
    "\n",
    "df = pd.DataFrame.from_dict(parse_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c97849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of the terrible things I'm doing below, we ideally want to create a loop\n",
    "# that loops over the children nodes of the tree (adding the labels of these children nodes every time, combined into a \n",
    "# list/tuple), until it gets to a node without any children. We then want to store the list/tuple we created into an \n",
    "# overarching list and start anew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb6dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:00:01 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-02-17 14:00:01 INFO: Use device: cpu\n",
      "2022-02-17 14:00:01 INFO: Loading: tokenize\n",
      "2022-02-17 14:00:01 INFO: Loading: pos\n",
      "2022-02-17 14:00:01 INFO: Loading: constituency\n",
      "2022-02-17 14:00:02 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL CONSTITUENCY TREE: (ROOT (S (NP (EX There)) (VP (VBP are) (NP (DT no) (JJ absolute) (NNS claims))) (. .)))\n",
      "\n",
      "\n",
      "TOKENS IN TEXT: There are no absolute claims.\n",
      "PATHS FOR TOKENS:  [('S', 'NP', 'EX'), ('S', 'VP', 'VBP'), ('S', 'VP', 'NP', 'DT'), ('S', 'VP', 'NP', 'JJ'), ('S', 'VP', 'NP', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON EXAMPLE SENTENCE (PUNCTUATION DOESN'T GET A CONSTITUENCY PATH)\n",
    "import stanza\n",
    "\n",
    "sublabels= []\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
    "text = \"There are no absolute claims.\"\n",
    "doc = nlp(text)\n",
    "for sentence in doc.sentences:\n",
    "    print(\"FULL CONSTITUENCY TREE:\", sentence.constituency)\n",
    "    for child in sentence.constituency.children:\n",
    "#         print(\"LABEL\", child.label)\n",
    "        for subchild in child.children:\n",
    "#             print(\"LABEL\", subchild.label)\n",
    "            if subchild.label == \"NP\":\n",
    "                for subsubchild in subchild.children:\n",
    "#                     print(\"SUBLABEL\", subsubchild.label)                    \n",
    "                    if subsubchild.label != \"NP\" and subsubchild.label != \"VP\" and subsubchild.label != \"PP\" and subsubchild.label != \"ADJP\" and subsubchild.label != \"ADVP\":\n",
    "                        sub_l = child.label, subchild.label, subsubchild.label\n",
    "                        sublabels.append(sub_l)\n",
    "                    else:\n",
    "                        for subsubsubchild in subsubchild.children:\n",
    "                            if subsubsubchild.label != \"NP\" and subsubsubchild.label != \"VP\" and subsubsubchild.label != \"PP\":\n",
    "                                sub_l = child.label, subchild.label, subsubchild.label, subsubsubchild.label\n",
    "                                sublabels.append(sub_l)\n",
    "                    \n",
    "            if subchild.label == \"VP\":\n",
    "                for subsubchild in subchild.children:\n",
    "#                     print(\"SUBLABEL\", subsubchild.label)\n",
    "                    if subsubchild.label != \"NP\" and subsubchild.label != \"VP\" and subsubchild.label != \"PP\" and subsubchild.label != \"ADJP\" and subsubchild.label != \"ADVP\":\n",
    "                        sub_l = child.label, subchild.label, subsubchild.label\n",
    "                        sublabels.append(sub_l)\n",
    "                    else:\n",
    "                        for subsubsubchild in subsubchild.children:\n",
    "                            if subsubsubchild.label != \"NP\" and subsubsubchild.label != \"VP\" and subsubsubchild.label != \"PP\":\n",
    "                                sub_l = child.label, subchild.label, subsubchild.label, subsubsubchild.label\n",
    "                                sublabels.append(sub_l)\n",
    "print(\"\\n\")\n",
    "print(\"TOKENS IN TEXT:\", text)\n",
    "print(\"PATHS FOR TOKENS: \", sublabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935485f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:01:02 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-02-17 14:01:02 INFO: Use device: cpu\n",
      "2022-02-17 14:01:02 INFO: Loading: tokenize\n",
      "2022-02-17 14:01:02 INFO: Loading: pos\n",
      "2022-02-17 14:01:03 INFO: Loading: constituency\n",
      "2022-02-17 14:01:03 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATHS:  [('S', 'NP', 'DT'), ('S', 'NP', 'JJ'), ('S', 'NP', 'NN'), ('S', 'VP', 'VBZ'), ('S', 'VP', 'VP', 'VBN'), ('S', 'NP', 'DT'), ('S', 'NP', 'NNP'), ('S', 'VP', 'VBZ'), ('S', 'VP', 'ADVP', '``'), ('S', 'VP', 'ADJP', 'ADJP'), ('S', 'VP', 'ADJP', \"''\"), ('S', 'NP', 'NP', 'DT'), ('S', 'NP', 'NP', 'JJ'), ('S', 'NP', 'NP', 'NN'), ('S', 'NP', 'PP', 'IN'), ('S', 'VP', 'VBZ'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VBG'), ('S', 'NP', 'DT'), ('S', 'NP', 'NNS'), ('S', 'VP', 'VBP'), ('S', 'VP', 'S'), ('S', 'NP', 'NN'), ('S', 'NP', 'NNS'), ('S', 'VP', 'VBD'), ('S', 'VP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'VP', 'VP', 'S'), ('S', 'NP', 'NP', 'JJ'), ('S', 'NP', 'NP', 'NN'), ('S', 'NP', 'PP', 'IN'), ('S', 'VP', 'MD'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'NP', 'NN'), ('S', 'NP', 'VP', 'VBN'), ('S', 'NP', 'VP', 'PRT'), ('S', 'VP', 'MD'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'NP', 'DT'), ('S', 'NP', 'VP', 'VBG'), ('S', 'NP', 'VP', 'S'), ('S', 'VP', 'MD'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'NP', 'DT'), ('S', 'NP', 'NP', 'NNS'), ('S', 'NP', 'PP', 'IN'), ('S', 'VP', 'VBP'), ('S', 'VP', 'VP', 'VBN'), ('S', 'VP', 'VP', 'S'), ('S', 'NP', 'DT'), ('S', 'NP', 'NN'), ('S', 'NP', 'S'), ('S', 'VP', 'MD'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'JJ'), ('S', 'NP', 'NNS'), ('S', 'VP', 'MD'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'NML'), ('S', 'NP', 'NNP'), ('S', 'NP', 'NNP'), ('S', 'VP', 'VBD'), ('S', 'VP', 'PP', 'IN'), ('S', 'VP', 'SBAR'), ('S', 'NP', 'NP', 'DT'), ('S', 'NP', 'NP', 'JJ'), ('S', 'NP', 'NP', 'NN'), ('S', 'NP', 'VP', 'VBG'), ('S', 'VP', 'VBZ'), ('S', 'VP', 'SBAR'), ('S', 'NP', 'PRP'), ('S', 'VP', 'MD'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'NP', 'PRP'), ('S', 'VP', 'VBD'), ('S', 'VP', 'VP', 'VBN'), ('S', 'VP', 'VP', 'SBAR'), ('S', 'NP', 'NP', 'NN'), ('S', 'NP', 'NP', 'NNS'), ('S', 'NP', ','), ('S', 'NP', 'NP', 'NNS'), ('S', 'NP', 'CC'), ('S', 'VP', 'MD'), ('S', 'VP', 'ADVP', 'RB'), ('S', 'VP', 'VP', 'VB'), ('S', 'VP', 'VP', 'ADJP'), ('S', 'NP', 'DT'), ('S', 'NP', 'NN'), ('S', 'NP', 'NNP'), ('S', 'VP', 'VP', 'VBD'), ('S', 'VP', 'VP', 'SBAR'), ('S', 'VP', ','), ('S', 'VP', 'SBAR'), ('S', 'NP', 'DT'), ('S', 'NP', 'NNP'), ('S', 'VP', 'VBZ'), ('S', 'VP', 'S'), ('S', 'NP', 'DT'), ('S', 'NP', 'NNP'), ('S', 'VP', 'MD'), ('S', 'VP', 'VP', 'VB'), ('S', 'VP', 'VP', 'S'), ('S', 'VP', 'VP', ','), ('S', 'VP', 'VP', 'SBAR'), ('S', 'NP', 'NNS'), ('S', 'VP', 'VBD'), ('S', 'NP', 'PRP'), ('S', 'VP', 'VBD')]\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON FULL ARTICLE\n",
    "\n",
    "import stanza\n",
    "\n",
    "sublabels= []\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
    "doc = nlp(content)\n",
    "for sentence in doc.sentences:\n",
    "    for child in sentence.constituency.children:\n",
    "#         print(\"LABEL\", child.label)\n",
    "        for subchild in child.children:\n",
    "#             print(\"LABEL\", subchild.label)\n",
    "            if subchild.label == \"NP\":\n",
    "                for subsubchild in subchild.children:\n",
    "#                     print(\"SUBLABEL\", subsubchild.label)                    \n",
    "                    if subsubchild.label != \"NP\" and subsubchild.label != \"VP\" and subsubchild.label != \"PP\" and subsubchild.label != \"ADJP\" and subsubchild.label != \"ADVP\":\n",
    "                        sub_l = child.label, subchild.label, subsubchild.label\n",
    "                        sublabels.append(sub_l)\n",
    "                    else:\n",
    "                        for subsubsubchild in subsubchild.children:\n",
    "                            if subsubsubchild.label != \"NP\" and subsubsubchild.label != \"VP\" and subsubsubchild.label != \"PP\":\n",
    "                                sub_l = child.label, subchild.label, subsubchild.label, subsubsubchild.label\n",
    "                                sublabels.append(sub_l)\n",
    "                    \n",
    "            if subchild.label == \"VP\":\n",
    "                for subsubchild in subchild.children:\n",
    "#                     print(\"SUBLABEL\", subsubchild.label)\n",
    "                    if subsubchild.label != \"NP\" and subsubchild.label != \"VP\" and subsubchild.label != \"PP\" and subsubchild.label != \"ADJP\" and subsubchild.label != \"ADVP\":\n",
    "                        sub_l = child.label, subchild.label, subsubchild.label\n",
    "                        sublabels.append(sub_l)\n",
    "                    else:\n",
    "                        for subsubsubchild in subsubchild.children:\n",
    "                            if subsubsubchild.label != \"NP\" and subsubsubchild.label != \"VP\" and subsubsubchild.label != \"PP\":\n",
    "                                sub_l = child.label, subchild.label, subsubchild.label, subsubsubchild.label\n",
    "                                sublabels.append(sub_l)\n",
    "print(\"PATHS: \", sublabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4796a940",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (113) does not match length of index (629)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2212/3414722054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# SO THIS GIVES A VALUE ERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"paths\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msublabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (113) does not match length of index (629)"
     ]
    }
   ],
   "source": [
    "# BECAUSE NOT EVERY TOKEN IS GETTING A PATH CURRENTLY,\n",
    "# WE CANNOT ADD THE CONSTITUENCY PATHS TO THE DATAFRAME YET\n",
    "# SO THIS GIVES A VALUE ERROR\n",
    "\n",
    "df[\"paths\"] = sublabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ea27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
